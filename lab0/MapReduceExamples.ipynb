{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82OvPKEiEqjc"
   },
   "source": [
    "# Введение в MapReduce модель на Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JQ2cvXLjICmI"
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple # requires python 3.6+\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yjPHumVwEyEg"
   },
   "outputs": [],
   "source": [
    "def MAP(_, row:NamedTuple):\n",
    "  if (row.gender == 'female'):\n",
    "    yield (row.age, row)\n",
    "\n",
    "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
    "  sum = 0\n",
    "  count = 0\n",
    "  for row in rows:\n",
    "    sum += row.social_contacts\n",
    "    count += 1\n",
    "  if (count > 0):\n",
    "    yield (age, sum/count)\n",
    "  else:\n",
    "    yield (age, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBKMgpG_ilaZ"
   },
   "source": [
    "Модель элемента данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Rv-XIjhTJPx3"
   },
   "outputs": [],
   "source": [
    "class User(NamedTuple):\n",
    "  id: int\n",
    "  age: str\n",
    "  social_contacts: int\n",
    "  gender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5KV0Ze2vQgu5"
   },
   "outputs": [],
   "source": [
    "input_collection = [\n",
    "    User(id=0, age=55, gender='male', social_contacts=20),\n",
    "    User(id=1, age=25, gender='female', social_contacts=240),\n",
    "    User(id=2, age=25, gender='female', social_contacts=500),\n",
    "    User(id=3, age=33, gender='female', social_contacts=800)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFeqzyZxZIFZ"
   },
   "source": [
    "Функция RECORDREADER моделирует чтение элементов с диска или по сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S5HR4E_GQoMJ"
   },
   "outputs": [],
   "source": [
    "def RECORDREADER():\n",
    "  return [(u.id, u) for u in input_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "NeEoWla-ROUy",
    "outputId": "94ca6e0e-4644-4282-acbf-1759d7ba2918"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, User(id=0, age=55, social_contacts=20, gender='male')),\n",
       " (1, User(id=1, age=25, social_contacts=240, gender='female')),\n",
       " (2, User(id=2, age=25, social_contacts=500, gender='female')),\n",
       " (3, User(id=3, age=33, social_contacts=800, gender='female'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(RECORDREADER())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YB8orgPSZs8M"
   },
   "outputs": [],
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "74oyvDLaRmd5",
    "outputId": "c6147702-7153-47c7-a574-d5fe6abe29a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, User(id=1, age=25, social_contacts=240, gender='female')),\n",
       " (25, User(id=2, age=25, social_contacts=500, gender='female')),\n",
       " (33, User(id=3, age=33, social_contacts=800, gender='female'))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
    "map_output = list(map_output) # materialize\n",
    "map_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8ncYDJ3-VzDn"
   },
   "outputs": [],
   "source": [
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "cKzY_6COWOA2",
    "outputId": "e6791b12-e409-47e9-bcd4-e9f8ca8611bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25,\n",
       "  [User(id=1, age=25, social_contacts=240, gender='female'),\n",
       "   User(id=2, age=25, social_contacts=500, gender='female')]),\n",
       " (33, [User(id=3, age=33, social_contacts=800, gender='female')])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_output = groupbykey(map_output)\n",
    "shuffle_output = list(shuffle_output)\n",
    "shuffle_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NlA7lkDDYL0t",
    "outputId": "6b25d03f-5c92-4f3b-f500-6d70acd598b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 370.0), (33, 800.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_output = flatten(map(lambda x: REDUCE(*x), shuffle_output))\n",
    "reduce_output = list(reduce_output)\n",
    "reduce_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf6qhHEtd6bI"
   },
   "source": [
    "Все действия одним конвейером!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dZaQGYxCdpw5",
    "outputId": "3f5c6425-e5c5-49d2-b2cd-ce58a9acc33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 370.0), (33, 800.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER()))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq3EWRIpwSiJ"
   },
   "source": [
    "# **MapReduce**\n",
    "Выделим общую для всех пользователей часть системы в отдельную функцию высшего порядка. Это наиболее простая модель MapReduce, без учёта распределённого хранения данных.\n",
    "\n",
    "Пользователь для решения своей задачи реализует RECORDREADER, MAP, REDUCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V1PZeQMwwVjc"
   },
   "outputs": [],
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "  return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFIVrimep678"
   },
   "source": [
    "## Спецификация MapReduce\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "f (k1, v1) -> (k2,v2)*\n",
    "g (k2, v2*) -> (k3,v3)*\n",
    "\n",
    "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "groupby ((k2,v2)*) -> (k2,v2*)*\n",
    "flatten (e2**) -> e2*\n",
    "\n",
    "mapreduce .map(f).flatten.groupby(k2).map(g).flatten\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtTFyqke3KGe"
   },
   "source": [
    "# Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNhh5763w5Vn"
   },
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QkyurnvGxBGk",
    "outputId": "84761282-d2ba-435a-e8d7-a85150730e10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 370.0), (33, 800.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import NamedTuple # requires python 3.6+\n",
    "from typing import Iterator\n",
    "\n",
    "class User(NamedTuple):\n",
    "  id: int\n",
    "  age: str\n",
    "  social_contacts: int\n",
    "  gender: str\n",
    "\n",
    "input_collection = [\n",
    "    User(id=0, age=55, gender='male', social_contacts=20),\n",
    "    User(id=1, age=25, gender='female', social_contacts=240),\n",
    "    User(id=2, age=25, gender='female', social_contacts=500),\n",
    "    User(id=3, age=33, gender='female', social_contacts=800)\n",
    "]\n",
    "\n",
    "def MAP(_, row:NamedTuple):\n",
    "  if (row.gender == 'female'):\n",
    "    yield (row.age, row)\n",
    "\n",
    "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
    "  sum = 0\n",
    "  count = 0\n",
    "  for row in rows:\n",
    "    sum += row.social_contacts\n",
    "    count += 1\n",
    "  if (count > 0):\n",
    "    yield (age, sum/count)\n",
    "  else:\n",
    "    yield (age, 0)\n",
    "\n",
    "def RECORDREADER():\n",
    "  return [(u.id, u) for u in input_collection]\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNKYIeerx0nY"
   },
   "source": [
    "## Matrix-Vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "rwcntRcCyi1V",
    "outputId": "606737ab-6b55-455c-931f-4fc45155f8a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.1039735826236234),\n",
       " (1, 1.1039735826236234),\n",
       " (2, 1.1039735826236234),\n",
       " (3, 1.1039735826236234),\n",
       " (4, 1.1039735826236234)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "\n",
    "mat = np.ones((5,4))\n",
    "vec = np.random.rand(4) # in-memory vector in all map tasks\n",
    "\n",
    "def MAP(coordinates:(int, int), value:int):\n",
    "  i, j = coordinates\n",
    "  yield (i, value*vec[j])\n",
    "\n",
    "def REDUCE(i:int, products:Iterator[NamedTuple]):\n",
    "  sum = 0\n",
    "  for p in products:\n",
    "    sum += p\n",
    "  yield (i, sum)\n",
    "\n",
    "def RECORDREADER():\n",
    "  for i in range(mat.shape[0]):\n",
    "    for j in range(mat.shape[1]):\n",
    "      yield ((i, j), mat[i,j])\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruZREYdi2o4O"
   },
   "source": [
    "## Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "vt9H9Alf3TYv",
    "outputId": "51aeffc9-e111-4607-bd84-cfcc7b56f238"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('it', ['0', '1', '2']),\n",
       " ('what', ['0', '1']),\n",
       " ('is', ['0', '1', '2']),\n",
       " ('banana', ['2']),\n",
       " ('a', ['2'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"it is what it is\"\n",
    "d2 = \"what is it\"\n",
    "d3 = \"it is a banana\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "def RECORDREADER():\n",
    "  for (docid, document) in enumerate(documents):\n",
    "    yield (\"{}\".format(docid), document)\n",
    "\n",
    "def MAP(docId:str, body:str):\n",
    "  for word in set(body.split(' ')):\n",
    "    yield (word, docId)\n",
    "\n",
    "def REDUCE(word:str, docIds:Iterator[str]):\n",
    "  yield (word, sorted(docIds))\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7az-6DA6qr2"
   },
   "source": [
    "## WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dN-nbtgG6uYG",
    "outputId": "24117576-7931-401d-a581-28e246b23453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 3), ('it', 9), ('is', 9), ('what', 5), ('a', 1), ('banana', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "def RECORDREADER():\n",
    "  for (docid, document) in enumerate(documents):\n",
    "    for (lineid, line) in enumerate(document.split('\\n')):\n",
    "      yield (\"{}:{}\".format(docid,lineid), line)\n",
    "\n",
    "def MAP(docId:str, line:str):\n",
    "  for word in line.split(\" \"):\n",
    "    yield (word, 1)\n",
    "\n",
    "def REDUCE(word:str, counts:Iterator[int]):\n",
    "  sum = 0\n",
    "  for c in counts:\n",
    "    sum += c\n",
    "  yield (word, sum)\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-jRAcYCAkkk"
   },
   "source": [
    "# MapReduce Distributed\n",
    "\n",
    "Добавляется в модель фабрика RECORDREARER-ов --- INPUTFORMAT, функция распределения промежуточных результатов по партициям PARTITIONER, и функция COMBINER для частичной аггрегации промежуточных результатов до распределения по новым партициям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nw-b-xJsApgW"
   },
   "outputs": [],
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "  global reducers\n",
    "  partitions = [dict() for _ in range(reducers)]\n",
    "  for map_partition in map_partitions:\n",
    "    for (k2, v2) in map_partition:\n",
    "      p = partitions[PARTITIONER(k2)]\n",
    "      p[k2] = p.get(k2, []) + [v2]\n",
    "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
    "\n",
    "def PARTITIONER(obj):\n",
    "  global reducers\n",
    "  return hash(obj) % reducers\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
    "  if COMBINER != None:\n",
    "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
    "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
    "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
    "\n",
    "  print(\"{} key-value pairs were sent over a network.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "  return reduce_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxirlf3XqZxY"
   },
   "source": [
    "## Спецификация MapReduce Distributed\n",
    "\n",
    "\n",
    "```\n",
    "f (k1, v1) -> (k2,v2)*\n",
    "g (k2, v2*) -> (k3,v3)*\n",
    "\n",
    "e1 (k1, v1)\n",
    "e2 (k2, v2)\n",
    "partition1 (k2, v2)*\n",
    "partition2 (k2, v2*)*\n",
    "\n",
    "flatmap (e1->e2*, e1*) -> partition1*\n",
    "groupby (partition1*) -> partition2*\n",
    "\n",
    "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "mapreduce .flatmap(f).groupby(k2).flatmap(g)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWYw_CpbbY3C"
   },
   "source": [
    "## WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "uR_zfGFkMZlp",
    "outputId": "c8d46167-473d-43b9-881a-2396991b3731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, [('', 6), ('a', 2), ('it', 18)]),\n",
       " (1, [('banana', 2), ('is', 18), ('what', 10)])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3, d1, d2, d3]\n",
    "\n",
    "maps = 3\n",
    "reducers = 2\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  global maps\n",
    "\n",
    "  def RECORDREADER(split):\n",
    "    for (docid, document) in enumerate(split):\n",
    "      for (lineid, line) in enumerate(document.split('\\n')):\n",
    "        yield (\"{}:{}\".format(docid,lineid), line)\n",
    "\n",
    "  split_size =  int(np.ceil(len(documents)/maps))\n",
    "  for i in range(0, len(documents), split_size):\n",
    "    yield RECORDREADER(documents[i:i+split_size])\n",
    "\n",
    "def MAP(docId:str, line:str):\n",
    "  for word in line.split(\" \"):\n",
    "    yield (word, 1)\n",
    "\n",
    "def REDUCE(word:str, counts:Iterator[int]):\n",
    "  sum = 0\n",
    "  for c in counts:\n",
    "    sum += c\n",
    "  yield (word, sum)\n",
    "\n",
    "# try to set COMBINER=REDUCER and look at the number of values sent over the network\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None)\n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCJGx8IQ87xS"
   },
   "source": [
    "## TeraSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "P2v8v1v_8_YR",
    "outputId": "e0987c25-9757-46cb-8e55-d5d2adfbee2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [(None, 0.055129211195594774),\n",
       "   (None, 0.07925688920363771),\n",
       "   (None, 0.09064987360443677),\n",
       "   (None, 0.09148848522085562),\n",
       "   (None, 0.09682056727627142),\n",
       "   (None, 0.14491593412427406),\n",
       "   (None, 0.20297443652491798),\n",
       "   (None, 0.2480858360914654),\n",
       "   (None, 0.2537229374018709),\n",
       "   (None, 0.28950450689780405),\n",
       "   (None, 0.34440582895563554),\n",
       "   (None, 0.405737883729819),\n",
       "   (None, 0.42172209356424184),\n",
       "   (None, 0.4572520977157871),\n",
       "   (None, 0.48478063470768107)]),\n",
       " (1,\n",
       "  [(None, 0.5036335391648709),\n",
       "   (None, 0.5677680272338165),\n",
       "   (None, 0.5752160094889407),\n",
       "   (None, 0.6407727432807331),\n",
       "   (None, 0.7227600328327994),\n",
       "   (None, 0.7326172273862329),\n",
       "   (None, 0.7328114209433377),\n",
       "   (None, 0.749511608312456),\n",
       "   (None, 0.7581711100809285),\n",
       "   (None, 0.7840849896627914),\n",
       "   (None, 0.7918416250152475),\n",
       "   (None, 0.8645413518693091),\n",
       "   (None, 0.8801243943357836),\n",
       "   (None, 0.9319552769638385),\n",
       "   (None, 0.9323374250868336)])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_values = np.random.rand(30)\n",
    "maps = 3\n",
    "reducers = 2\n",
    "min_value = 0.0\n",
    "max_value = 1.0\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  global maps\n",
    "\n",
    "  def RECORDREADER(split):\n",
    "    for value in split:\n",
    "        yield (value, None)\n",
    "\n",
    "  split_size =  int(np.ceil(len(input_values)/maps))\n",
    "  for i in range(0, len(input_values), split_size):\n",
    "    yield RECORDREADER(input_values[i:i+split_size])\n",
    "\n",
    "def MAP(value:int, _):\n",
    "  yield (value, None)\n",
    "\n",
    "def PARTITIONER(key):\n",
    "  global reducers\n",
    "  global max_value\n",
    "  global min_value\n",
    "  bucket_size = (max_value-min_value)/reducers\n",
    "  bucket_id = 0\n",
    "  while((key>(bucket_id+1)*bucket_size) and ((bucket_id+1)*bucket_size<max_value)):\n",
    "    bucket_id += 1\n",
    "  return bucket_id\n",
    "\n",
    "def REDUCE(value:int, _):\n",
    "  yield (None,value)\n",
    "\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None, PARTITIONER=PARTITIONER)\n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQhoJaVZI93G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy65YJTH99iT"
   },
   "source": [
    "# Упражнения\n",
    "Упражнения взяты из Rajaraman A., Ullman J. D. Mining of massive datasets. – Cambridge University Press, 2011.\n",
    "\n",
    "\n",
    "Для выполнения заданий переопределите функции RECORDREADER, MAP, REDUCE. Для модели распределённой системы может потребоваться переопределение функций PARTITION и COMBINER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfvAeZm3S8S8"
   },
   "source": [
    "### Максимальное значение ряда\n",
    "\n",
    "Разработайте MapReduce алгоритм, который находит максимальное число входного списка чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3GRA1JR-Tkbg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное значение: 9\n"
     ]
    }
   ],
   "source": [
    "def RECORDREADER(input_list):\n",
    "    return [(1, num) for num in input_list]\n",
    "\n",
    "\n",
    "def MAP(_, num):\n",
    "    yield (None, num)\n",
    "\n",
    "\n",
    "def REDUCE(_, nums):\n",
    "    yield (None, max(nums))\n",
    "\n",
    "\n",
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "def groupbykey(iterable):\n",
    "    t = {}\n",
    "    for (k, v) in iterable:\n",
    "        t[k] = t.get(k, []) + [v]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "input_list = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]\n",
    "\n",
    "records = RECORDREADER(input_list)\n",
    "\n",
    "mapped_values = flatten(MAP(_, num) for _, num in records)\n",
    "\n",
    "grouped_values = groupbykey(mapped_values)\n",
    "\n",
    "reduced_values_list = list(flatten(REDUCE(k, v) for k, v in grouped_values))\n",
    "\n",
    "if reduced_values_list:\n",
    "    print(\"Максимальное значение:\", reduced_values_list[0][1])\n",
    "else:\n",
    "    print(\"Список пуст\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k86bXnqZTk-U"
   },
   "source": [
    "### Арифметическое среднее\n",
    "\n",
    "Разработайте MapReduce алгоритм, который находит арифметическое среднее.\n",
    "\n",
    "$$\\overline{X} = \\frac{1}{n}\\sum_{i=0}^{n} x_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MPoY5pkfUNZf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Арифметическое среднее: 3.5\n"
     ]
    }
   ],
   "source": [
    "def RECORDREADER(input_list):\n",
    "    return [(1, num) for num in input_list]\n",
    "\n",
    "def MAP(_, value):\n",
    "    yield (None, (value, 1))\n",
    "\n",
    "def REDUCE(_, values):\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    for value, count in values:\n",
    "        total_sum += value\n",
    "        total_count += count\n",
    "    average = total_sum / total_count if total_count > 0 else 0\n",
    "    yield (None, average)\n",
    "\n",
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "    t = {}\n",
    "    for (k, v) in iterable:\n",
    "        t[k] = t.get(k, []) + [v]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "input_list = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "records = RECORDREADER(input_list)\n",
    "\n",
    "mapped = flatten(MAP(_, value) for _, value in records)\n",
    "\n",
    "grouped = groupbykey(mapped)\n",
    "\n",
    "reduced = flatten(REDUCE(k, v) for k, v in grouped)\n",
    "\n",
    "average_value = list(reduced)[0][1]\n",
    "print(\"Арифметическое среднее:\", average_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xanzszhsIlLe"
   },
   "source": [
    "### GroupByKey на основе сортировки\n",
    "\n",
    "Реализуйте groupByKey на основе сортировки, проверьте его работу на примерах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hQPn3USsIkEC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 75), (1, 31), (1, 15), (1, 29), (1, 60), (1, 60), (1, 87), (1, 68), (1, 4), (1, 65)]\n",
      "[(1, [75, 31, 15, 29, 60, 60, 87, 68, 4, 65])]\n",
      "[49.4]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def flatten(lst):\n",
    "    return list(chain.from_iterable(lst))\n",
    "\n",
    "def MAP(input_data):\n",
    "    return (1, input_data)\n",
    "\n",
    "def groupbykey(items):\n",
    "    sorted_items = sorted(items, key=lambda x: x[0])\n",
    "    grouped = {}\n",
    "    for key, value in sorted_items:\n",
    "        if key in grouped:\n",
    "            grouped[key].append(value)\n",
    "        else:\n",
    "            grouped[key] = [value]\n",
    "    return [(k, list(v)) for k, v in grouped.items()]\n",
    "\n",
    "\n",
    "def REDUCE(key, values):\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    for value in values:\n",
    "        total_sum += value\n",
    "        total_count += 1\n",
    "    average = total_sum / total_count if total_count > 0 else 0\n",
    "    return average\n",
    "\n",
    "def RECORDREADER(count):\n",
    "    return [random.randint(0, 100) for i in range(count)]\n",
    "\n",
    "\n",
    "mapped_data = map_output = list(map(lambda x: MAP(x), RECORDREADER(10)))\n",
    "\n",
    "print(mapped_data)\n",
    "\n",
    "shuffle_output = groupbykey(mapped_data)\n",
    "\n",
    "print(shuffle_output)\n",
    "\n",
    "reduce_output = list(map(lambda x: REDUCE(*x), shuffle_output))\n",
    "print(reduce_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SgEjCZyGnu6"
   },
   "source": [
    "### Drop duplicates (set construction, unique elements, distinct)\n",
    "\n",
    "Реализуйте распределённую операцию исключения дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "okjbyApjGhMt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, ['', 'a', 'it']), (1, ['banana', 'is', 'what'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "  global reducers\n",
    "  partitions = [dict() for _ in range(reducers)]\n",
    "  for map_partition in map_partitions:\n",
    "    for (k2, v2) in map_partition:\n",
    "      p = partitions[PARTITIONER(k2)]\n",
    "      p[k2] = p.get(k2, []) + [v2]\n",
    "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
    "\n",
    "def PARTITIONER(obj):\n",
    "  global reducers\n",
    "  return hash(obj) % reducers\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
    "  if COMBINER != None:\n",
    "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
    "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
    "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
    "\n",
    "  print(\"{} key-value pairs were sent over a network.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "  return reduce_outputs\n",
    "\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "\n",
    "documents = [d1, d2, d3, d1, d2, d3]\n",
    "\n",
    "maps = 3\n",
    "reducers = 2\n",
    "\n",
    "def INPUTFORMAT():\n",
    "    global maps\n",
    "    split_size = int(np.ceil(len(documents) / maps))\n",
    "    for i in range(0, len(documents), split_size):\n",
    "        yield (\n",
    "            (\"{}:{}\".format(docid, lineid), line)\n",
    "            for docid, document in enumerate(documents[i:i+split_size])\n",
    "            for lineid, line in enumerate(document.split('\\n'))\n",
    "        )\n",
    "\n",
    "def MAP(docId:str, line:str):\n",
    "  for word in line.split(\" \"):\n",
    "    yield (word, word)\n",
    "\n",
    "def REDUCE(key:str, value:Iterator[str]):\n",
    "  yield key\n",
    "\n",
    "# try to set COMBINER=REDUCER and look at the number of values sent over the network\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None)\n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7sRGoTXuJze"
   },
   "source": [
    "#Операторы реляционной алгебры\n",
    "### Selection (Выборка)\n",
    "\n",
    "**The Map Function**: Для  каждого кортежа $t \\in R$ вычисляется истинность предиката $C$. В случае истины создаётся пара ключ-значение $(t, t)$. В паре ключ и значение одинаковы, равны $t$.\n",
    "\n",
    "**The Reduce Function:** Роль функции Reduce выполняет функция идентичности, которая возвращает то же значение, что получила на вход.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4nKIKe59uIfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(87, 97, 35), (6, 69, 69), (22, 100, 57), (65, 62, 53), (30, 56, 8), (82, 37, 5), (89, 90, 73), (53, 24, 92), (51, 3, 74), (31, 45, 89)]\n",
      "[(87, 97, 35), (89, 90, 73)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def MAP(el_list):\n",
    "    mapped_result = {t: [t] for t in el_list if C(t)}\n",
    "    return mapped_result.items()\n",
    "\n",
    "def REDUCE(mapped_items):\n",
    "    return [key for key, _ in mapped_items]\n",
    "\n",
    "def C(t):\n",
    "    return sum(t) > 200\n",
    "    \n",
    "def RECORDREADER(count):\n",
    "    return [(random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)) for i in range(count)]\n",
    "\n",
    "record = RECORDREADER(10)\n",
    "\n",
    "print(record)\n",
    "\n",
    "part_count = 5\n",
    "record_partitional = [record[i:i + part_count] for i in range(0, len(record), part_count)]\n",
    "\n",
    "reduced_output = REDUCE([item for sublist in map(MAP, record_partitional) for item in sublist])\n",
    "print(reduced_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w27Ca-_Ku85V"
   },
   "source": [
    "### Projection (Проекция)\n",
    "\n",
    "Проекция на множество атрибутов $S$.\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $t \\in R$ создайте кортеж $t′$, исключая  из $t$ те значения, атрибуты которых не принадлежат  $S$. Верните пару $(t′, t′)$.\n",
    "\n",
    "**The Reduce Function:** Для каждого ключа $t′$, созданного любой Map задачей, вы получаете одну или несколько пар $(t′, t′)$. Reduce функция преобразует $(t′, [t′, t′, . . . , t′])$ в $(t′, t′)$, так, что для ключа $t′$ возвращается одна пара  $(t′, t′)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BEvuY4GqvhS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(89, 70, 45), (39, 71, 69), (77, 12, 17), (46, 58, 77), (51, 15, 97)]\n",
      "[((), ()), ((), ()), ((), ()), ((), ()), ((15,), (15,))]\n",
      "[((), [(), (), (), ()]), ((15,), [(15,)])]\n",
      "[(), (15,)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import NamedTuple, Iterator, List, Tuple, Set\n",
    "\n",
    "S: Set[int] = {1, 3, 5, 7, 9, 11, 13, 15}\n",
    "\n",
    "TupleType = Tuple[int, int, int]\n",
    "\n",
    "def MAP(t: TupleType) -> Tuple[Tuple[int, ...], Tuple[int, ...]]:\n",
    "    res = tuple(el for el in t if el in S)\n",
    "    return (res, res)\n",
    "\n",
    "def REDUCE(key: Tuple[int, ...], values: Iterator[NamedTuple]) -> Tuple[int, ...]:\n",
    "    return (key, key)\n",
    "\n",
    "def RECORDREADER(count: int) -> List[TupleType]:\n",
    "    return [(random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)) for _ in range(count)]\n",
    "\n",
    "def group_by_key(iterable: List[Tuple[Tuple[int, ...], Tuple[int, ...]]]) -> List[Tuple[Tuple[int, ...], List[Tuple[int, ...]]]]:\n",
    "    grouped = {}\n",
    "    for k, v in iterable:\n",
    "        grouped.setdefault(k, []).append(v)\n",
    "    return grouped.items()\n",
    "\n",
    "record = RECORDREADER(5)\n",
    "map_output = [MAP(x) for x in record]\n",
    "\n",
    "shuffle_output = list(group_by_key(map_output))\n",
    "\n",
    "reduce_output = [REDUCE(key, values)[0] for key, values in shuffle_output]\n",
    "\n",
    "print(record)\n",
    "print(map_output)\n",
    "print(shuffle_output)\n",
    "print(reduce_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gau6lKXvn2R"
   },
   "source": [
    "### Union (Объединение)\n",
    "\n",
    "**The Map Function:** Превратите каждый входной кортеж $t$ в пару ключ-значение $(t, t)$.\n",
    "\n",
    "**The Reduce Function:** С каждым ключом $t$ будет ассоциировано одно или два значений. В обоих случаях создайте $(t, t)$ в качестве выходного значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Sns7a5agv3nw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record:\n",
      " [(37, 13, 29), (71, 98, 74), (14, 54, 54)]\n",
      "Map Output:\n",
      " [((37, 13, 29), (37, 13, 29)), ((71, 98, 74), (71, 98, 74)), ((14, 54, 54), (14, 54, 54))]\n",
      "Shuffle Output:\n",
      " [((37, 13, 29), [(37, 13, 29)]), ((71, 98, 74), [(71, 98, 74)]), ((14, 54, 54), [(14, 54, 54)])]\n",
      "Reduce Output:\n",
      " [(37, 13, 29), (71, 98, 74), (14, 54, 54)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple, Iterator\n",
    "\n",
    "TupleType = Tuple[int, int, int]\n",
    "\n",
    "def MAP(t: TupleType) -> Tuple[TupleType, TupleType]:\n",
    "    return (t, t)\n",
    "\n",
    "def REDUCE(key: TupleType, values: Iterator[TupleType]) -> Tuple[TupleType, TupleType]:\n",
    "    return (key, key)\n",
    "\n",
    "def RECORDREADER(count: int) -> List[TupleType]:\n",
    "    return [(random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)) for _ in range(count)]\n",
    "\n",
    "def group_by_key(iterable: List[Tuple[TupleType, TupleType]]) -> List[Tuple[TupleType, List[TupleType]]]:\n",
    "    t = {}\n",
    "    for k2, v2 in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return list(t.items())\n",
    "\n",
    "\n",
    "record = RECORDREADER(3)\n",
    "map_output = [MAP(x) for x in record]\n",
    "\n",
    "shuffle_output = list(group_by_key(map_output))\n",
    "\n",
    "reduce_output = [REDUCE(key, values)[0] for key, values in shuffle_output]\n",
    "\n",
    "print(\"Record:\\n\", record)\n",
    "print(\"Map Output:\\n\", map_output)\n",
    "print(\"Shuffle Output:\\n\", shuffle_output)\n",
    "print(\"Reduce Output:\\n\", reduce_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ8TuEbjv4J8"
   },
   "source": [
    "### Intersection (Пересечение)\n",
    "\n",
    "**The Map Function:** Превратите каждый кортеж $t$ в пары ключ-значение $(t, t)$.\n",
    "\n",
    "**The Reduce Function:** Если для ключа $t$ есть список из двух элементов $[t, t]$ $-$ создайте пару $(t, t)$. Иначе, ничего не создавайте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XKlBZh4IwERR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record:\n",
      " [(1, 0), (1, 0), (2, 2)]\n",
      "Map Output:\n",
      " [((1, 0), (1, 0)), ((1, 0), (1, 0)), ((2, 2), (2, 2))]\n",
      "Shuffle Output:\n",
      " [((1, 0), [(1, 0), (1, 0)]), ((2, 2), [(2, 2)])]\n",
      "Reduce Output:\n",
      " [((1, 0), (1, 0))]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Iterator, Tuple\n",
    "\n",
    "def MAP(t: Tuple[int, int]) -> Tuple[Tuple[int, int], Tuple[int, int]]:\n",
    "    return (t, t)\n",
    "\n",
    "def REDUCE(key: Tuple[int, int], values: list) -> Tuple[Tuple[int, int], Tuple[int, int]]:\n",
    "    if len(values) == 2:\n",
    "        return (key, key)\n",
    "\n",
    "def RECORDREADER(count: int) -> list:\n",
    "    return [(random.randint(0, 3), random.randint(0, 3)) for _ in range(count)]\n",
    "\n",
    "def group_by_key(iterable: list) -> list:\n",
    "    grouped = {}\n",
    "    for key, value in iterable:\n",
    "        grouped.setdefault(key, []).append(value)\n",
    "    return grouped.items()\n",
    "\n",
    "\n",
    "record = RECORDREADER(3)\n",
    "map_output = [MAP(x) for x in record]\n",
    "\n",
    "shuffle_output = list(group_by_key(map_output))\n",
    "\n",
    "reduce_output = [REDUCE(*item) for item in shuffle_output if REDUCE(*item) is not None]\n",
    "\n",
    "print(\"Record:\\n\", record)\n",
    "print(\"Map Output:\\n\", map_output)\n",
    "print(\"Shuffle Output:\\n\", shuffle_output)\n",
    "print(\"Reduce Output:\\n\", [item for item in reduce_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVOpqoY3wE5k"
   },
   "source": [
    "### Difference (Разница)\n",
    "\n",
    "**The Map Function:** Для кортежа $t \\in R$, создайте пару $(t, R)$, и для кортежа $t \\in S$, создайте пару $(t, S)$. Задумка заключается в том, чтобы значение пары было именем отношения $R$ or $S$, которому принадлежит кортеж (а лучше, единичный бит, по которому можно два отношения различить $R$ or $S$), а не весь набор атрибутов отношения.\n",
    "\n",
    "**The Reduce Function:** Для каждого ключа $t$, если соответствующее значение является списком $[R]$, создайте пару $(t, t)$. В иных случаях не предпринимайте действий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "QE_AC09lwZIZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record:\n",
      "[((1, 2), 0), ((0, 2), 0), ((1, 2), 0), ((0, 0), 0), ((1, 2), 0)]\n",
      "Map Output:\n",
      "[((1, 2), 0), ((0, 2), 0), ((1, 2), 0), ((0, 0), 0), ((1, 2), 0)]\n",
      "Shuffle and Group Output:\n",
      "[((1, 2), [0, 0, 0]), ((0, 2), [0]), ((0, 0), [0])]\n",
      "Reduce Output:\n",
      "[((1, 2), (1, 2)), ((0, 2), (0, 2)), ((0, 0), (0, 0))]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "REL_R = 0\n",
    "REL_S = 1\n",
    "\n",
    "def get_random_tuple() -> Tuple[Tuple[int, int], int]:\n",
    "    data = (random.randint(0, 3), random.randint(0, 3))\n",
    "    rel_id = random.choice([REL_R, REL_S])\n",
    "    return (data, rel_id)\n",
    "\n",
    "def RECORDREADER(count: int) -> List[Tuple[Tuple[int, int], int]]:\n",
    "    return [get_random_tuple() for _ in range(count)]\n",
    "\n",
    "def MAP(t: Tuple[Tuple[int, int], int]) -> Tuple[Tuple[int, int], int]:\n",
    "    return t\n",
    "\n",
    "def REDUCE(key: Tuple[int, int], values: List[int]) -> Tuple[Tuple[int, int], Tuple[int, int]]:\n",
    "    if all(value == REL_R for value in values):\n",
    "        return (key, key)\n",
    "\n",
    "def group_by_key(iterable: List[Tuple[Tuple[int, int], int]]) -> dict:\n",
    "    grouped = defaultdict(list)\n",
    "    for key, value in iterable:\n",
    "        grouped[key].append(value)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "record = RECORDREADER(5)\n",
    "map_output = [MAP(x) for x in record]\n",
    "grouped_output = group_by_key(map_output)\n",
    "reduce_output = [REDUCE(key, values) for key, values in grouped_output.items() if REDUCE(key, values)]\n",
    "\n",
    "print(f\"Record:\\n{record}\")\n",
    "print(f\"Map Output:\\n{map_output}\")\n",
    "print(f\"Shuffle and Group Output:\\n{list(grouped_output.items())}\")\n",
    "print(f\"Reduce Output:\\n{reduce_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8I58V2VwhSm"
   },
   "source": [
    "### Natural Join\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $(a, b)$ отношения $R$, создайте пару $(b,(R, a))$. Для каждого кортежа $(b, c)$ отношения $S$, создайте пару $(b,(S, c))$.\n",
    "\n",
    "**The Reduce Function:** Каждый ключ $b$ будет асоциирован со списком пар, которые принимают форму либо $(R, a)$, либо $(S, c)$. Создайте все пары, одни, состоящие из  первого компонента $R$, а другие, из первого компонента $S$, то есть $(R, a)$ и $(S, c)$. На выходе вы получаете последовательность пар ключ-значение из списков ключей и значений. Ключ не нужен. Каждое значение, это тройка $(a, b, c)$ такая, что $(R, a)$ и $(S, c)$ это принадлежат входному списку значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "yHiuuTctw86I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record:\n",
      "[(0, (1, 1)), (0, (0, 2)), (0, (3, 0)), (1, (2, 2)), (1, (0, 3)), (1, (2, 3)), (1, (3, 3))]\n",
      "Map Output:\n",
      "[(1, ('R', 1)), (2, ('R', 0)), (0, ('R', 3)), (2, ('S', 2)), (0, ('S', 3)), (2, ('S', 3)), (3, ('S', 3))]\n",
      "Grouped Output:\n",
      "[(1, [('R', 1)]), (2, [('R', 0), ('S', 2), ('S', 3)]), (0, [('R', 3), ('S', 3)]), (3, [('S', 3)])]\n",
      "Reduce Output:\n",
      "[(0, 2, 2), (0, 2, 3), (3, 0, 3)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "REL_R = 0\n",
    "REL_S = 1\n",
    "\n",
    "def get_random_tuple(rel_id: int) -> Tuple[int, Tuple[int, int]]:\n",
    "    return (rel_id, (random.randint(0, 3), random.randint(0, 3)))\n",
    "\n",
    "def RECORDREADER(count: int) -> List[Tuple[int, Tuple[int, int]]]:\n",
    "    return [get_random_tuple(REL_R if i < count // 2 else REL_S) for i in range(count)]\n",
    "\n",
    "def MAP(t: Tuple[int, Tuple[int, int]]) -> Tuple[int, Tuple[int, int]]:\n",
    "    rel_id, data = t\n",
    "    if rel_id == REL_R:\n",
    "        return (data[1], ('R', data[0]))\n",
    "    else:\n",
    "        return (data[0], ('S', data[1]))\n",
    "\n",
    "def REDUCE(key: int, values: List[Tuple[str, int]]) -> List[Tuple[int, int, int]]:\n",
    "    result = []\n",
    "    r_values = [v[1] for v in values if v[0] == 'R']\n",
    "    s_values = [v[1] for v in values if v[0] == 'S']\n",
    "    for r in r_values:\n",
    "        for s in s_values:\n",
    "            result.append((r, key, s))\n",
    "    return result\n",
    "\n",
    "def group_by_key(iterable: List[Tuple[int, Tuple[str, int]]]) -> dict:\n",
    "    grouped = {}\n",
    "    for key, value in iterable:\n",
    "        grouped.setdefault(key, []).append(value)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "record = RECORDREADER(7)\n",
    "map_output = [MAP(x) for x in record]\n",
    "grouped_output = group_by_key(map_output)\n",
    "reduce_output = [item for sublist in map(lambda x: REDUCE(*x), grouped_output.items()) for item in sublist]\n",
    "\n",
    "print(f\"Record:\\n{record}\")\n",
    "print(f\"Map Output:\\n{map_output}\")\n",
    "print(f\"Grouped Output:\\n{list(grouped_output.items())}\")\n",
    "print(f\"Reduce Output:\\n{reduce_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYdlr0YUxE27"
   },
   "source": [
    "### Grouping and Aggregation (Группировка и аггрегация)\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $(a, b, c$) создайте пару $(a, b)$.\n",
    "\n",
    "**The Reduce Function:** Ключ представляет ту или иную группу. Примение аггрегирующую операцию $\\theta$ к списку значений $[b1, b2, . . . , bn]$ ассоциированных с ключом $a$. Возвращайте в выходной поток $(a, x)$, где $x$ результат применения  $\\theta$ к списку. Например, если $\\theta$ это $SUM$, тогда $x = b1 + b2 + · · · + bn$, а если $\\theta$ is $MAX$, тогда $x$ это максимальное из значений $b1, b2, . . . , bn$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "MLPckfEGxico"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 2, 1), (2, 0, 1), (0, 0, 0), (0, 2, 0), (2, 2, 1), (3, 1, 2), (1, 0, 2), (1, 1, 1), (1, 2, 3), (1, 3, 1)]\n",
      "[(3, 2), (2, 0), (0, 0), (0, 2), (2, 2), (3, 1), (1, 0), (1, 1), (1, 2), (1, 3)]\n",
      "dict_items([(3, [2, 1]), (2, [0, 2]), (0, [0, 2]), (1, [0, 1, 2, 3])])\n",
      "Sum Reduce Output:\n",
      "[(3, 3), (2, 2), (0, 2), (1, 6)]\n",
      "Max Reduce Output:\n",
      "[(3, 2), (2, 2), (0, 2), (1, 3)]\n",
      "Min Reduce Output:\n",
      "[(3, 1), (2, 0), (0, 0), (1, 0)]\n",
      "Avg Reduce Output:\n",
      "[(3, 1.5), (2, 1.0), (0, 1.0), (1, 1.5)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple, Dict, Any, Iterator\n",
    "\n",
    "def get_random_tuple() -> Tuple[int, int, int]:\n",
    "    return (random.randint(0, 3), random.randint(0, 3), random.randint(0, 3))\n",
    "\n",
    "def RECORDREADER(count: int) -> List[Tuple[int, int, int]]:\n",
    "    return [get_random_tuple() for _ in range(count)]\n",
    "\n",
    "def MAP(t: Tuple[int, int, int]) -> Tuple[int, int]:\n",
    "    return (t[0], t[1])\n",
    "\n",
    "def theta_aggregate(values: List[int], mode: str) -> Any:\n",
    "    if mode == 'sum':\n",
    "        return sum(values)\n",
    "    elif mode == 'max':\n",
    "        return max(values)\n",
    "    elif mode == 'min':\n",
    "        return min(values)\n",
    "    elif mode == 'avg':\n",
    "        return sum(values) / len(values) if values else 0\n",
    "\n",
    "def REDUCE(key: int, values: List[int], mode: str) -> Tuple[int, Any]:\n",
    "    aggregated_value = theta_aggregate(values, mode)\n",
    "    return (key, aggregated_value)\n",
    "\n",
    "def group_by_key(iterable: List[Tuple[int, int]]) -> Dict[int, List[int]]:\n",
    "    t = {}\n",
    "    for k, v in iterable:\n",
    "        t[k] = t.get(k, []) + [v]\n",
    "    return t.items()\n",
    "\n",
    "record = RECORDREADER(10)\n",
    "\n",
    "print(record)\n",
    "\n",
    "map_output = [MAP(x) for x in record]\n",
    "\n",
    "print(map_output)\n",
    "shuffle_output = group_by_key(map_output)\n",
    "print(shuffle_output)\n",
    "aggregations = ['sum', 'max', 'min', 'avg']\n",
    "for agg in aggregations:\n",
    "    reduce_output = [REDUCE(key, values, agg) for key, values in shuffle_output]\n",
    "    print(f\"{agg.capitalize()} Reduce Output:\\n{reduce_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03IffTEOJgOb"
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIrRgvG4RIS4"
   },
   "source": [
    "### Matrix-Vector multiplication\n",
    "\n",
    "Случай, когда вектор не помещается в памяти Map задачи\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQhDbiL3zS9r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIo2t7nNxvA9"
   },
   "source": [
    "## Matrix multiplication (Перемножение матриц)\n",
    "\n",
    "Если у нас есть матрица $M$ с элементами $m_{ij}$ в строке $i$ и столбце $j$, и матрица $N$ с элементами $n_{jk}$ в строке $j$ и столбце $k$, тогда их произведение $P = MN$ есть матрица $P$ с элементами $p_{ik}$ в строке $i$ и столбце $k$, где\n",
    "\n",
    "$$p_{ik} =\\sum_{j} m_{ij}n_{jk}$$\n",
    "\n",
    "Необходимым требованием является одинаковое количество столбцов в $M$ и строк в $N$, чтобы операция суммирования по  $j$ была осмысленной. Мы можем размышлять о матрице, как об отношении с тремя атрибутами: номер строки, номер столбца, само значение. Таким образом матрица $M$ предстваляется как отношение $ M(I, J, V )$, с кортежами $(i, j, m_{ij})$, и, аналогично, матрица $N$ представляется как отношение $N(J, K, W)$, с кортежами $(j, k, n_{jk})$. Так как большие матрицы как правило разреженные (большинство значений равно 0), и так как мы можем нулевыми значениями пренебречь (не хранить), такое реляционное представление достаточно эффективно для больших матриц. Однако, возможно, что координаты $i$, $j$, и $k$ неявно закодированы в смещение позиции элемента относительно начала файла, вместо явного хранения. Тогда, функция Map (или Reader) должна быть разработана таким образом, чтобы реконструировать компоненты $I$, $J$, и $K$ кортежей из смещения.\n",
    "\n",
    "Произведение $MN$ это фактически join, за которым следуют группировка по ключу и аггрегация. Таким образом join отношений $M(I, J, V )$ и $N(J, K, W)$, имеющих общим только атрибут $J$, создаст кортежи $(i, j, k, v, w)$ из каждого кортежа $(i, j, v) \\in M$ и кортежа $(j, k, w) \\in N$. Такой 5 компонентный кортеж представляет пару элементов матрицы $(m_{ij} , n_{jk})$. Что нам хотелось бы получить на самом деле, это произведение этих элементов, то есть, 4 компонентный кортеж$(i, j, k, v \\times w)$, так как он представляет произведение $m_{ij}n_{jk}$. Мы представляем отношение как результат одной MapReduce операции, в которой мы можем произвести группировку и аггрегацию, с $I$ и $K$  атрибутами, по которым идёт группировка, и суммой  $V \\times W$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1MBkGaLAYVCt"
   },
   "outputs": [],
   "source": [
    "# MapReduce model\n",
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "  return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMspsOT0ZB35"
   },
   "source": [
    "Реализуйте перемножение матриц с использованием модельного кода MapReduce для одной машины в случае, когда одна матрица хранится в памяти, а другая генерируется RECORDREADER-ом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "psP1XekbsEjS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4*10\n",
    "small_mat = np.random.rand(I,J)\n",
    "big_mat = np.random.rand(J,K)\n",
    "\n",
    "def RECORDREADER():\n",
    "  for j in range(big_mat.shape[0]):\n",
    "    for k in range(big_mat.shape[1]):\n",
    "      yield ((j,k), big_mat[j,k])\n",
    "\n",
    "def MAP(k1, v1):\n",
    "  (j, k) = k1\n",
    "  w = v1\n",
    "  for i in range(small_mat.shape[0]):\n",
    "    yield ((i,k), small_mat[i,j]*w)\n",
    "\n",
    "def REDUCE(key, values):\n",
    "  (i, k) = key\n",
    "  result = sum(values)\n",
    "  yield ((i,k), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnt306LHhHrm"
   },
   "source": [
    "Проверьте своё решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ewy_ZNYqW5a2",
    "outputId": "9ce264f2-9412-44e2-9b0a-cc780573ab3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK THE SOLUTION\n",
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "solution = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "\n",
    "def asmatrix(reduce_output):\n",
    "  reduce_output = list(reduce_output)\n",
    "  I = max(i for ((i,k), vw) in reduce_output)+1\n",
    "  K = max(k for ((i,k), vw) in reduce_output)+1\n",
    "  mat = np.empty(shape=(I,K))\n",
    "  for ((i,k), vw) in reduce_output:\n",
    "    mat[i,k] = vw\n",
    "  return mat\n",
    "\n",
    "np.allclose(reference_solution, asmatrix(solution)) # should return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TK7v4CEcfxqf",
    "outputId": "2c865d0a-4065-4e6b-c83f-5508ed5eb4fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_output = list(MapReduce(RECORDREADER, MAP, REDUCE))\n",
    "max(i for ((i,k), vw) in reduce_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4yyg3kOZqJJ"
   },
   "source": [
    "Реализуйте перемножение матриц  с использованием модельного кода MapReduce для одной машины в случае, когда обе матрицы генерируются в RECORDREADER. Например, сначала одна, а потом другая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3B7rIAJCaHZq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4*10\n",
    "small_mat = np.random.rand(I,J)\n",
    "big_mat = np.random.rand(J,K)\n",
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "\n",
    "def RECORDREADER():\n",
    "    yield from (((0, i, j), value) for i, row in enumerate(small_mat) for j, value in enumerate(row))\n",
    "    yield from (((1, j, k), value) for j, row in enumerate(big_mat) for k, value in enumerate(row))\n",
    "\n",
    "\n",
    "def MAP_JOIN(k1, v1):\n",
    "    mat_num, i, j = k1\n",
    "    key = j if mat_num == 0 else i\n",
    "    yield (key, (mat_num, i if mat_num == 0 else j, v1))\n",
    "\n",
    "\n",
    "def REDUCE_JOIN(key, values):\n",
    "    for v1 in values:\n",
    "        if v1[0] == 0:\n",
    "            for v2 in values:\n",
    "                if v2[0] == 1:\n",
    "                    yield ((v1[1], v2[1]), v1[2] * v2[2])\n",
    "\n",
    "def MAP_MUL(k1, v1):\n",
    "    yield k1, v1\n",
    "\n",
    "\n",
    "def REDUCE_MUL(key, values):\n",
    "    yield (key, sum(values))\n",
    "\n",
    "\n",
    "def GET_JOINED():\n",
    "    yield from joined\n",
    "\n",
    "joined = MapReduce(RECORDREADER, MAP_JOIN, REDUCE_JOIN)\n",
    "solution = MapReduce(GET_JOINED, MAP_MUL, REDUCE_MUL)\n",
    "np.allclose(reference_solution, asmatrix(solution)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXyzQi1DaIwo"
   },
   "source": [
    "Реализуйте перемножение матриц с использованием модельного кода MapReduce Distributed, когда каждая матрица генерируется в своём RECORDREADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "TDM_s78Rb5eR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 key-value pairs were sent over a network.\n",
      "240 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "  global reducers\n",
    "  partitions = [dict() for _ in range(reducers)]\n",
    "  for map_partition in map_partitions:\n",
    "    for (k2, v2) in map_partition:\n",
    "      p = partitions[PARTITIONER(k2)]\n",
    "      p[k2] = p.get(k2, []) + [v2]\n",
    "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
    "\n",
    "def PARTITIONER(obj):\n",
    "  global reducers\n",
    "  return hash(obj) % reducers\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
    "  if COMBINER != None:\n",
    "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
    "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
    "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
    "\n",
    "  print(\"{} key-value pairs were sent over a network.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "  return reduce_outputs\n",
    "\n",
    "\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4*10\n",
    "small_mat = np.random.rand(I,J)\n",
    "big_mat = np.random.rand(J,K)\n",
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "\n",
    "def INPUTFORMAT():\n",
    "    first_mat = [((0, i, j), value) for i, row in enumerate(small_mat) for j, value in enumerate(row)]\n",
    "    second_mat = [((1, j, k), value) for j, row in enumerate(big_mat) for k, value in enumerate(row)]\n",
    "    return [first_mat, second_mat]\n",
    "\n",
    "\n",
    "\n",
    "def MAP_JOIN(k1, v1):\n",
    "    mat_num, i, j = k1\n",
    "    key = j if mat_num == 0 else i\n",
    "    yield (key, (mat_num, i if mat_num == 0 else j, v1))\n",
    "\n",
    "\n",
    "def REDUCE_JOIN(key, values):\n",
    "    for v1 in values:\n",
    "        if v1[0] == 0:\n",
    "            for v2 in values:\n",
    "                if v2[0] == 1:\n",
    "                    yield ((v1[1], v2[1]), v1[2] * v2[2])\n",
    "\n",
    "\n",
    "def GET_JOINED():\n",
    "  yield from (j[1] for j in joined)\n",
    "\n",
    "\n",
    "def MAP_MUL(k1, v1): #+\n",
    "    yield k1, v1\n",
    "\n",
    "\n",
    "def REDUCE_MUL(key, values):\n",
    "    yield (key, sum(values))\n",
    "\n",
    "maps = 8\n",
    "reducers = 4\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP_JOIN, REDUCE_JOIN, COMBINER=None)\n",
    "joined = list(map(lambda x: (x[0], list(x[1])), partitioned_output))\n",
    "\n",
    "mul_output = MapReduceDistributed(GET_JOINED, MAP_MUL, REDUCE_MUL, COMBINER=None)\n",
    "pre_result = list(map(lambda x: (x[0], list(x[1])), mul_output))\n",
    "\n",
    "solution = [v for p in pre_result for v in p[1]]\n",
    "\n",
    "np.allclose(reference_solution, asmatrix(solution)) # should return true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuSA2P9Db6UM"
   },
   "source": [
    "Обобщите предыдущее решение на случай, когда каждая матрица генерируется несколькими RECORDREADER-ами, и проверьте его работоспособность. Будет ли работать решение, если RECORDREADER-ы будут генерировать случайное подмножество элементов матрицы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ehN0FqRDcwU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 key-value pairs were sent over a network.\n",
      "240 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "  global reducers\n",
    "  partitions = [dict() for _ in range(reducers)]\n",
    "  for map_partition in map_partitions:\n",
    "    for (k2, v2) in map_partition:\n",
    "      p = partitions[PARTITIONER(k2)]\n",
    "      p[k2] = p.get(k2, []) + [v2]\n",
    "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
    "\n",
    "def PARTITIONER(obj):\n",
    "  global reducers\n",
    "  return hash(obj) % reducers\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
    "  if COMBINER != None:\n",
    "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
    "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
    "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
    "\n",
    "  print(\"{} key-value pairs were sent over a network.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "  return reduce_outputs\n",
    "\n",
    "\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4*10\n",
    "small_mat = np.random.rand(I,J)\n",
    "big_mat = np.random.rand(J,K)\n",
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  first_mat = [((0, i, j), small_mat[i,j]) for i in range(small_mat.shape[0]) for j in range(small_mat.shape[1])]\n",
    "\n",
    "  second_mat = [((1, j, k), big_mat[j,k]) for j in range(big_mat.shape[0]) for k in range(big_mat.shape[1])]\n",
    "\n",
    "  # Разбиваем первую матрицу на части\n",
    "  split_size = int(np.ceil(len(first_mat)/maps))\n",
    "  for i in range(0, len(first_mat), split_size):\n",
    "    yield first_mat[i:i+split_size]\n",
    "\n",
    "  # Разбиваем вторую матрицу на части\n",
    "  split_size = int(np.ceil(len(second_mat)/maps))\n",
    "  for i in range(0, len(second_mat), split_size):\n",
    "    yield second_mat[i:i+split_size]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MAP_JOIN(k1, v1):\n",
    "    mat_num, i, j = k1\n",
    "    key = j if mat_num == 0 else i\n",
    "    yield (key, (mat_num, i if mat_num == 0 else j, v1))\n",
    "\n",
    "\n",
    "def REDUCE_JOIN(key, values):\n",
    "    for v1 in values:\n",
    "        if v1[0] == 0:\n",
    "            for v2 in values:\n",
    "                if v2[0] == 1:\n",
    "                    yield ((v1[1], v2[1]), v1[2] * v2[2])\n",
    "\n",
    "\n",
    "def GET_JOINED():\n",
    "  yield from (j[1] for j in joined)\n",
    "\n",
    "\n",
    "def MAP_MUL(k1, v1): #+\n",
    "    yield k1, v1\n",
    "\n",
    "\n",
    "def REDUCE_MUL(key, values):\n",
    "    yield (key, sum(values))\n",
    "\n",
    "maps = 8\n",
    "reducers = 4\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP_JOIN, REDUCE_JOIN, COMBINER=None)\n",
    "joined = list(map(lambda x: (x[0], list(x[1])), partitioned_output))\n",
    "\n",
    "mul_output = MapReduceDistributed(GET_JOINED, MAP_MUL, REDUCE_MUL, COMBINER=None)\n",
    "pre_result = list(map(lambda x: (x[0], list(x[1])), mul_output))\n",
    "\n",
    "solution = [v for p in pre_result for v in p[1]]\n",
    "\n",
    "np.allclose(reference_solution, asmatrix(solution)) # should return true"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
